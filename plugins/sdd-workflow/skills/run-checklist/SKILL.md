---
name: run-checklist
description: "Automatically verify checklist items generated by /checklist command. Runs tests, linters, security scanners, and spec consistency checks to validate implementation against quality criteria."
version: 1.0.0
license: MIT
user-invocable: true
allowed-tools: Read, Write, Edit, Glob, Grep, Bash, TaskCreate, TaskUpdate, TaskList, TaskGet
---

# Run Checklist - Automated Quality Verification

Automatically execute verification commands for checklist items and record results.

## Prerequisites

**Read the following prerequisite references before execution:**

- `references/prerequisites_plugin_update.md` - Check for plugin updates
- `references/prerequisites_principles.md` - Read AI-SDD principles document
- `references/prerequisites_directory_paths.md` - Resolve directory paths using `SDD_*` environment variables

### Language Configuration

Templates are located under `templates/${SDD_LANG:-en}/` within this skill directory.
The `SDD_LANG` environment variable determines the language (default: `en`).

### Required Prerequisites

| Prerequisite   | Verification                             | Command to Generate              |
|:---------------|:-----------------------------------------|:---------------------------------|
| **Checklist**  | `.sdd/task/{ticket}/checklist.md` exists | `/checklist {feature} {ticket}`  |

## Input

$ARGUMENTS

| Argument        | Required | Description                                                          |
|:----------------|:---------|:---------------------------------------------------------------------|
| `feature-name`  | Yes      | Target feature name or path (e.g., `user-auth`, `auth/user-login`)   |
| `ticket-number` | -        | Task directory name. Uses feature-name if omitted                    |
| `--category`    | -        | Run only specific category (e.g., `--category testing`)              |
| `--priority`    | -        | Run only specific priority level (e.g., `--priority P1`)             |

### Input Format

```
/run-checklist {feature-name} {ticket-number}
/run-checklist {feature-name}  # Uses feature-name as ticket directory
/run-checklist {feature-name} {ticket-number} --category testing
/run-checklist {feature-name} {ticket-number} --priority P1
```

## Processing Flow

### 1. Load Checklist

Load the checklist file from `.sdd/task/{ticket}/checklist.md`.

Parse each checklist item:
- Extract CHK-ID (e.g., CHK-501)
- Extract priority level (P1, P2, P3)
- Extract verification commands from code blocks
- Identify category from ID prefix (CHK-1xx = Requirements, CHK-5xx = Testing, etc.)

### 2. Detect Project Environment

Detect project type and available tools:

| Detection Target   | Check Method                                   |
|:-------------------|:-----------------------------------------------|
| Package Manager    | Check for `package.json`, `Cargo.toml`, etc.   |
| Test Framework     | Parse config files (jest, pytest, etc.)        |
| Linter             | Check for `.eslintrc`, `ruff.toml`, etc.       |
| Type Checker       | Check for `tsconfig.json`, `mypy.ini`, etc.    |
| Security Scanner   | Check for audit commands availability          |

### 3. Execute Automated Verifications

Read `references/verification_commands.md` for the verification command mapping table.

#### Verification Categories

| Category (CHK-xxx)         | Auto-Verifiable | Verification Method                        |
|:---------------------------|:----------------|:-------------------------------------------|
| Requirements (1xx)         | Partial         | `/check-spec` for spec consistency         |
| Specification (2xx)        | Partial         | Type checking, API signature validation    |
| Design (3xx)               | Partial         | Dependency analysis, architecture checks   |
| Implementation (4xx)       | Yes             | Linter, static analysis                    |
| Testing (5xx)              | Yes             | Test execution, coverage measurement       |
| Documentation (6xx)        | Partial         | Doc coverage tools                         |
| Security (7xx)             | Yes             | Security scanners, audit commands          |
| Performance (8xx)          | Partial         | Benchmark tools (if configured)            |
| Deployment (9xx)           | Partial         | Config validation                          |

### 4. Record Results

Read `templates/${SDD_LANG:-en}/result_format.md` for the result format template.

Update checklist file with verification results:
- Mark verified items with `[x]` or `[ ]`
- Add verification timestamp
- Include command output summary

### 5. Generate Report

Read `templates/${SDD_LANG:-en}/report_format.md` for the report format template.

Output verification summary to `.sdd/task/{ticket}/verification_report.md`.

## Output Format

### Updated Checklist

Original checklist items are updated with verification status:

```markdown
### CHK-501 [P1] Unit Test Coverage

- [x] Unit tests exist for all business logic ✅ Verified: 2024-01-15
- [x] Code coverage >= 80% ✅ Verified: 85.2% coverage
- [x] All public functions are tested ✅ Verified: 2024-01-15
- [ ] Edge cases are covered ⚠️ Manual verification required

**Automated Verification Result**:
- Command: `npm test -- --coverage`
- Status: PASSED
- Coverage: 85.2% (lines), 78.5% (branches)
- Executed: 2024-01-15 10:30:45
```

### Verification Report

Save to: `.sdd/task/{ticket}/verification_report.md`

## TaskList Integration

Use TaskList to track verification progress:

1. Create tasks for each verification category being run
2. Update task status as each category completes
3. Mark completed when all verifications finish

Read `templates/${SDD_LANG:-en}/tasklist_patterns.md` for TaskList usage patterns.

## Error Handling

### Test Failure

When tests fail, record the failure details and continue with other verifications:

```markdown
**Automated Verification Result**:
- Command: `npm test`
- Status: FAILED
- Failures: 3 tests failed
- Details: See test output below
- Executed: 2024-01-15 10:30:45
```

### Tool Not Available

When a verification tool is not configured:

```markdown
**Automated Verification Result**:
- Status: SKIPPED
- Reason: ESLint not configured in this project
- Suggestion: Add `.eslintrc` to enable linting verification
```

## Best Practices

| Practice                | Benefit                                              |
|:------------------------|:-----------------------------------------------------|
| **Run after implement** | Verify implementation meets quality criteria         |
| **Run before PR**       | Ensure all P1 items pass                             |
| **Use --priority P1**   | Quick pre-commit verification                        |
| **Review manual items** | Some items require human judgment                    |

## Integration with Other Commands

```
/generate-spec {feature}
   |
/task-breakdown {feature}
   |
/checklist {feature} {ticket}  <- Generate checklist
   |
/implement {feature} {ticket}  <- Implement feature
   |
/run-checklist {feature} {ticket}  <- Verify implementation
   |
Review verification report before PR
```

## Notes

- Not all checklist items can be automatically verified
- Manual verification items are marked for human review
- Results are appended to existing checklist, preserving manual checks
- Run with `--category` to focus on specific verification types
- Security scanners may require additional setup (npm audit, safety, etc.)
